# üí∏ Projeto MLOps: Detec√ß√£o de Fraudes em Transa√ß√µes Financeiras (Synthetic Fraud Detection)

Este projeto demonstra um pipeline MLOps completo, utilizando o **MLflow** para rastreamento, compara√ß√£o de modelos e otimiza√ß√£o de hiperpar√¢metros, focado em resolver um problema cl√°ssico de desbalanceamento de classes: a detec√ß√£o de fraudes.

## üéØ Objetivo de Neg√≥cio

O objetivo principal era criar um modelo que **minimizasse o Falso Negativo (maximizar o Recall)**, garantindo que o maior n√∫mero poss√≠vel de transa√ß√µes fraudulentas fosse capturado, mesmo que isso implicasse em mais Falsos Positivos.

## üíæ Metodologia e Dataset

* **Dataset:** Dataset p√∫blico de transa√ß√µes sint√©ticas (`vitaliy-sharandin/synthetic-fraud-detection`).
* **Amostragem:** Para otimizar o tempo de treinamento e demonstrar escalabilidade, foi utilizada uma amostra de **500.000 linhas** (de um total de 6.3M).
* **Desafio:** O dataset apresenta um desbalanceamento severo, com uma taxa de fraude de apenas **0.0466%**.

## üíª Ferramentas e Arquitetura

* **Framework:** Scikit-learn
* **Rastreamento MLOps:** MLflow (Registrando modelos, m√©tricas e par√¢metros)
* **Modelos Testados:** Regress√£o Log√≠stica e Random Forest Classifier

## üìä An√°lise de Desempenho e Conclus√£o

O processo de MLOps permitiu uma compara√ß√£o rigorosa entre os modelos, focada nas m√©tricas de **Recall** e **Precision** (acur√°cia √© enganosa devido ao desbalanceamento).

### 1. Compara√ß√£o de Modelos (RF vs. LR)

| Modelo | Recall M√°ximo | Precision no Recall M√°ximo |
| :--- | :---: | :---: |
| **Logistic Regression** | **89.36%** | **0.46%** (1 em 217 alertas era real) |
| **Random Forest (Final)** | 82.98% | **3.73%** (1 em 27 alertas era real) |

> **Conclus√£o:** O **Random Forest (RF)** foi o modelo escolhido. Embora a Regress√£o Log√≠stica tenha atingido um Recall ligeiramente maior (89.36%), sua Precision de apenas 0.46% tornaria o sistema inutiliz√°vel (a cada 200 alertas, 199 seriam falsos). O RF, por ser um modelo n√£o linear, conseguiu um Precision 7 vezes maior, sendo significativamente mais confi√°vel na pr√°tica.

### 2. Otimiza√ß√£o do Threshold (Limiar de Decis√£o)

O modelo RF final foi ajustado para atingir o objetivo de alta captura de fraudes, utilizando `class_weight='balanced'` e otimizando o limiar (`threshold`) de decis√£o.

| Par√¢metros de Otimiza√ß√£o | Precision | Recall | F1-Score | AUC-ROC |
| :--- | :---: | :---: | :---: | :---: |
| **RF Otimizado (Threshold = 0.05)** | 0.0373 | **0.8298** | 0.0714 | **0.9797** |

> **Resultado Final:** A Run com `Threshold = 0.05` foi selecionada como a melhor candidata, pois oferece **82.98% de Recall** (minimizando o Falso Negativo) com uma alta confian√ßa subjacente do modelo, confirmada por um **AUC-ROC de 0.9797** (excelente capacidade de discrimina√ß√£o).

### 3. Justificativa de Escopo (Amostragem)

> **Nota:** Todos os treinamentos foram realizados em uma amostra de **500.000 linhas**. O uso de uma amostra √© uma pr√°tica de MLOps para reduzir o tempo de itera√ß√£o e o custo computacional, permitindo que a diferen√ßa de desempenho entre os modelos fosse claramente demonstrada. √â esperado que o treinamento com o dataset completo de 6.3M amplie ainda mais a superioridade do Random Forest.

### 4. Visualiza√ß√£o do Trade-off Precision vs. Recall

O gr√°fico de dispers√£o abaixo ilustra o resultado da otimiza√ß√£o de modelos e limiares (Thresholds). Cada ponto representa uma Run do MLflow, e o tamanho/cor indica o F1-Score (equil√≠brio).

O objetivo era mover os pontos para cima (maior Recall).

![Gr√°fico de Dispers√£o Precision vs. Recall](precision_vs_recall_tradeoff.png)

## üîó Como Visualizar os Resultados

Para revisar todas as 21 itera√ß√µes de treinamento, m√©tricas e par√¢metros registrados, utilize o MLflow UI:

```bash
# Na raiz do projeto, com o venv ativo
mlflow ui
```

## üîö Conclus√£o:

Embora o escopo inicial envolvesse modelos lineares como a Regress√£o Log√≠stica (LR), o teste inicial com a LR demonstrou sua inefic√°cia diante do severo desbalanceamento (Precision < 1%). Por essa raz√£o, o projeto escalou para o Random Forest Classifier, um modelo n√£o linear mais robusto, que provou ser a ferramenta correta, alcan√ßando um Precision 7x maior e um AUC-ROC de 0.9797, provando a superioridade do modelo para este dom√≠nio financeiro.
